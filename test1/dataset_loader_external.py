# -*- coding: utf-8 -*-
"""
Dataset loader for external datasets (SMD, Buoy) - Experiment 6.

ç”¨äºåœ¨SMDå’ŒBuoyæ•°æ®é›†ä¸Šè®­ç»ƒUNetå’ŒCNNã€?
ä¸ä¸»è®­ç»ƒä»£ç çš„æ•°æ®åŠ è½½ç­–ç•¥ä¿æŒä¸€è‡´ã€?

æ”¯æŒä¸¤ç§æ¨¡å¼ï¼?
  - joint: è¿”å› (degraded_img, clean_img, seg_mask) ç”¨äºè”åˆè®­ç»ƒ
  - segmentation: è¿”å› (clean_img, seg_mask) ç”¨äºåˆ†å‰²è®­ç»ƒ

æ³¨æ„ï¼šç”±äºSMDå’ŒBuoyæ•°æ®é›†æœ¬èº«å°±åŒ…å«å„ç§é€€åŒ–ï¼ˆé›¾ã€é›¨ç­‰ï¼‰ï¼?
æ‰€ä»¥è¿™é‡Œçš„"clean"å›¾åƒå®é™…ä¸Šå°±æ˜¯åŸå›¾ï¼Œé€€åŒ–åˆæˆæ¯”ä¾‹è¾ƒä½ã€?
"""

import os
import random
from typing import Tuple, Optional

import cv2
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset


class ExternalDataset(Dataset):
    """
    Dataset for SMD/Buoy with on-the-fly degradation synthesis.
    
    CSVæ ¼å¼è¦æ±‚ï¼šimg_name,x1,y1,x2,y2
    """
    
    def __init__(
        self,
        csv_path: str,
        img_dir: str,
        img_size: Tuple[int, int] = (576, 1024),  # (H, W)
        mode: str = "joint",  # "joint" or "segmentation"
        augment: bool = False,
        p_clean: float = 0.35,  # ä¿æŒå¹²å‡€çš„æ¦‚ç?
    ):
        self.csv_path = csv_path
        self.img_dir = img_dir
        self.img_size = img_size
        self.mode = mode
        self.augment = augment
        self.p_clean = p_clean
        
        # åŠ è½½CSV
        self.df = pd.read_csv(csv_path)
        self.n_samples = len(self.df)
        
        # é€€åŒ–ç±»å‹ï¼ˆä¸ä¸»ä»£ç ä¸€è‡´ï¼šrain, fog, darkï¼?
        self.degradation_types = ["rain", "fog", "dark"]
    
    def __len__(self):
        return self.n_samples
    
    def __getitem__(self, idx: int):
        row = self.df.iloc[idx]
        img_name = str(row["img_name"])
        
        # è¯»å–å›¾åƒ
        img_path = os.path.join(self.img_dir, img_name)
        bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)
        if bgr is None:
            # è¿”å›ç©ºæ•°æ?
            h, w = self.img_size
            if self.mode == "segmentation":
                return torch.zeros(3, h, w), torch.zeros(h, w, dtype=torch.long)
            else:
                return torch.zeros(3, h, w), torch.zeros(3, h, w), torch.zeros(h, w, dtype=torch.long)
        
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
        
        # Resizeåˆ°ç›®æ ‡å°ºå¯?
        h, w = self.img_size
        rgb_resized = cv2.resize(rgb, (w, h), interpolation=cv2.INTER_AREA)
        
        # è·å–GTåæ ‡å¹¶ç¼©æ”?
        h_orig, w_orig = bgr.shape[:2]
        x1 = float(row["x1"]) * w / w_orig
        y1 = float(row["y1"]) * h / h_orig
        x2 = float(row["x2"]) * w / w_orig
        y2 = float(row["y2"]) * h / h_orig
        
        # ç”Ÿæˆåˆ†å‰²maskï¼ˆåŸºäºGTçº¿ï¼‰
        mask = self._generate_mask_from_line(x1, y1, x2, y2, h, w)
        
        # æ•°æ®å¢å¼º
        if self.augment:
            rgb_resized, mask = self._augment(rgb_resized, mask)
        
        # å½’ä¸€åŒ?
        clean_tensor = torch.from_numpy(rgb_resized.astype(np.float32) / 255.0).permute(2, 0, 1)
        mask_tensor = torch.from_numpy(mask.astype(np.int64))
        
        if self.mode == "segmentation":
            # åˆ†å‰²æ¨¡å¼ï¼šè¿”å›?(clean, mask)
            return clean_tensor, mask_tensor
        else:
            # Jointæ¨¡å¼ï¼šè¿”å›?(degraded, clean, mask)
            if random.random() < self.p_clean:
                # ä¿æŒå¹²å‡€
                input_tensor = clean_tensor.clone()
            else:
                # åº”ç”¨é€€åŒ?
                input_tensor = self._apply_degradation(clean_tensor)
            
            return input_tensor, clean_tensor, mask_tensor
    
    def _generate_mask_from_line(self, x1: float, y1: float, x2: float, y2: float, h: int, w: int) -> np.ndarray:
        """æ ¹æ®GTæ°´å¹³çº¿ç”Ÿæˆåˆ†å‰²maskï¼šä¸Šæ–¹ä¸ºsky(1)ï¼Œä¸‹æ–¹ä¸ºsea(0)"""
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # è®¡ç®—ç›´çº¿æ–¹ç¨‹ï¼šy = k*x + b
        if abs(x2 - x1) < 1e-6:
            # å‚ç›´çº¿ï¼ˆä¸å¤ªå¯èƒ½æ˜¯æ°´å¹³çº¿ï¼?
            return mask
        
        k = (y2 - y1) / (x2 - x1)
        b = y1 - k * x1
        
        # å¯¹æ¯ä¸€åˆ—xï¼Œè®¡ç®—yå€¼ï¼Œä¸Šæ–¹è®¾ä¸º1ï¼ˆskyï¼?
        for x in range(w):
            y_line = int(k * x + b)
            y_line = max(0, min(h - 1, y_line))
            mask[:y_line, x] = 1  # ä¸Šæ–¹æ˜¯sky
        
        return mask
    
    def _augment(self, img: np.ndarray, mask: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ç®€å•çš„æ•°æ®å¢å¼ºï¼šæ°´å¹³ç¿»è½?""
        if random.random() > 0.5:
            img = np.fliplr(img).copy()
            mask = np.fliplr(mask).copy()
        return img, mask
    
    def _apply_degradation(self, img_tensor: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨éšæœºé€€åŒ–ï¼ˆä¸ä¸»ä»£ç ä¸€è‡´ï¼‰"""
        deg_type = random.choice(self.degradation_types)
        
        img_np = (img_tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)
        
        if deg_type == "rain":
            img_np = self._add_rain(img_np)
        elif deg_type == "fog":
            img_np = self._add_fog(img_np)
        elif deg_type == "dark":
            img_np = self._add_dark(img_np)
        
        return torch.from_numpy(img_np.astype(np.float32) / 255.0).permute(2, 0, 1)
    
    def _add_rain(self, img: np.ndarray) -> np.ndarray:
        """æ·»åŠ é›¨æ•ˆæ?""
        h, w = img.shape[:2]
        rain = np.zeros((h, w), dtype=np.float32)
        
        # éšæœºé›¨æ»´
        n_drops = random.randint(100, 300)
        for _ in range(n_drops):
            x = random.randint(0, w - 1)
            y = random.randint(0, h - 1)
            length = random.randint(10, 30)
            angle = random.uniform(-0.1, 0.1)  # è¿‘ä¹å‚ç›´
            
            for l in range(length):
                yy = int(y + l)
                xx = int(x + l * angle)
                if 0 <= yy < h and 0 <= xx < w:
                    rain[yy, xx] = random.uniform(0.3, 0.8)
        
        # æ¨¡ç³Šé›¨æ»´
        rain = cv2.GaussianBlur(rain, (3, 3), 0)
        
        # å åŠ 
        rain_rgb = np.stack([rain, rain, rain], axis=-1) * 255
        result = np.clip(img.astype(np.float32) + rain_rgb * 0.5, 0, 255).astype(np.uint8)
        
        return result
    
    def _add_fog(self, img: np.ndarray) -> np.ndarray:
        """æ·»åŠ é›¾æ•ˆæ?""
        h, w = img.shape[:2]
        fog_intensity = random.uniform(0.2, 0.5)
        
        # æ¸å˜é›¾ï¼ˆä»ä¸Šåˆ°ä¸‹é€æ¸å‡å¼±ï¼?
        fog = np.linspace(fog_intensity, fog_intensity * 0.3, h).reshape(-1, 1)
        fog = np.tile(fog, (1, w))
        
        # æ·»åŠ éšæœºå™ªå£°
        noise = np.random.randn(h, w) * 0.05
        fog = np.clip(fog + noise, 0, 1).astype(np.float32)
        
        # é›¾è‰²ï¼ˆç°ç™½è‰²ï¼?
        fog_color = np.array([200, 200, 200], dtype=np.float32)
        
        result = img.astype(np.float32) * (1 - fog[:, :, None]) + fog_color * fog[:, :, None]
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def _add_dark(self, img: np.ndarray) -> np.ndarray:
        """é™ä½äº®åº¦"""
        factor = random.uniform(0.3, 0.6)
        result = (img.astype(np.float32) * factor).astype(np.uint8)
        return result


def load_external_split_indices(split_dir: str) -> dict:
    """åŠ è½½å¤–éƒ¨æ•°æ®é›†çš„splitç´¢å¼•"""
    result = {}
    for split in ["train", "val", "test"]:
        path = os.path.join(split_dir, f"{split}_indices.npy")
        if os.path.exists(path):
            result[split] = np.load(path).astype(np.int64).tolist()
        else:
            result[split] = []
    return result
