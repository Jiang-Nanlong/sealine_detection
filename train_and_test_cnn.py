import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
import matplotlib.pyplot as plt
import numpy as np
import cv2

# å¯¼å…¥ä½ çš„æ¨¡å—
from dataset_loader_gradient_radon_cnn import HorizonFusionDataset
from cnn_model import HorizonDetNet


def train_and_evaluate():
    # ================= é…ç½®å‚æ•° =================
    CSV_PATH = r"Hashmani's Dataset/GroundTruth.csv"
    IMG_DIR = r"Hashmani's Dataset/MU-SID"

    # è®­ç»ƒè¶…å‚æ•°
    BATCH_SIZE = 8
    LEARNING_RATE = 1e-4
    EPOCHS = 50  # å»ºè®®ç¨å¾®å¤šä¸€ç‚¹ï¼Œ30å¯èƒ½åˆšæ”¶æ•›

    # ç½‘ç»œè¾“å…¥å°ºå¯¸ (å¿…é¡»ä¸ Dataset é‡Œçš„ resize å¯¹åº”)
    RESIZE_H = 362  # Rho è½´ (å¯¹åº” Dataset çš„ resize_h)
    RESIZE_W = 180  # Theta è½´ (å¯¹åº” Dataset çš„ resize_w)

    # è¯„ä¼°ç”¨çš„åå½’ä¸€åŒ–å‚æ•°
    # å› ä¸º Dataset æŠŠ rho å½’ä¸€åŒ–åˆ°äº† [0,1]ï¼Œæˆ‘ä»¬éœ€è¦è¿˜åŸå›åƒç´ çœ‹è¯¯å·®
    # 1080P å›¾ç‰‡å¯¹è§’çº¿çº¦ä¸º 2203
    APPROX_MAX_DIAG = 2203.0
    MAX_THETA_DEG = 180.0

    # æ•°æ®é›†åˆ†å‰²ç‚¹
    SPLIT_INDEX = 2473
    # ===========================================

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # --- 1. åŠ è½½æ•°æ® ---
    print("ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†...")
    # å…³é”®ï¼šè¿™é‡Œ resize_h/w å¿…é¡»ä¼ å…¥ï¼Œç¡®ä¿ Dataset å†…éƒ¨ç¼©æ”¾æ­£ç¡®
    full_dataset = HorizonFusionDataset(CSV_PATH, IMG_DIR, resize_h=RESIZE_H, resize_w=RESIZE_W)
    total_len = len(full_dataset)
    print(f"ğŸ“Š æ•°æ®é›†æ€»æ•°: {total_len}")

    if total_len < SPLIT_INDEX:
        raise ValueError("æ•°æ®é›†æ•°é‡ä¸è¶³ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼")

    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
    train_dataset = Subset(full_dataset, range(0, SPLIT_INDEX))
    test_dataset = Subset(full_dataset, range(SPLIT_INDEX, total_len))

    # DataLoader (å¿…é¡» num_workers=0ï¼Œå› ä¸º Dataset ç”¨åˆ°äº† CUDA)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    # --- 2. æ£€æŸ¥æ•°æ®å½¢çŠ¶ (é˜²æ­¢è·‘ä¸€åŠæŠ¥é”™) ---
    first_batch, first_label = next(iter(train_loader))
    print(f"ğŸ” è¾“å…¥å½¢çŠ¶æ£€æŸ¥: {first_batch.shape}")  # åº”ä¸º [8, 3, 362, 180]
    print(f"ğŸ” æ ‡ç­¾å½¢çŠ¶æ£€æŸ¥: {first_label.shape}")  # åº”ä¸º [8, 2]

    if first_batch.shape[2] != RESIZE_H:
        raise ValueError(f"å°ºå¯¸ä¸åŒ¹é…ï¼Datasetè¾“å‡ºH={first_batch.shape[2]}, é¢„æœŸ{RESIZE_H}")

    # --- 3. åˆå§‹åŒ–æ¨¡å‹ ---
    # in_channels=3 å¯¹åº”ä¼ ç»Ÿæ–¹æ³•çš„ä¸‰ä¸ªå°ºåº¦
    model = HorizonDetNet(in_channels=3, img_h=RESIZE_H, img_w=RESIZE_W).to(device)

    # æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    # å­¦ä¹ ç‡è°ƒæ•´ï¼šæ¯ 15 è½®è¡°å‡ä¸€æ¬¡
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)

    # --- 4. è®­ç»ƒå¾ªç¯ ---
    loss_history = []
    print("\nğŸ”¥ å¼€å§‹è®­ç»ƒ...")

    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0

        for i, (inputs, labels) in enumerate(train_loader):
            inputs = inputs.to(device)
            labels = labels.to(device).float()  # æ ‡ç­¾å·²ç»åœ¨ Dataset é‡Œå½’ä¸€åŒ–åˆ° 0-1 äº†

            optimizer.zero_grad()
            outputs = model(inputs)  # è¾“å‡ºä¹Ÿæ˜¯é¢„æµ‹çš„ 0-1 å€¼

            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        epoch_loss = running_loss / len(train_loader)
        loss_history.append(epoch_loss)
        scheduler.step()

        # æ‰“å°è¿›åº¦
        current_lr = optimizer.param_groups[0]['lr']
        print(f"Epoch [{epoch + 1}/{EPOCHS}] | Loss: {epoch_loss:.6f} | LR: {current_lr:.6f}")

    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), "horizon_cnn_gpu.pth")
    print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: horizon_cnn_gpu.pth")

    # --- 5. è¯„ä¼° (Evaluation) ---
    print("\nğŸ§ª æ­£åœ¨è¯„ä¼°æµ‹è¯•é›†...")
    model.eval()

    total_mae_rho_pixel = 0.0
    total_mae_theta_degree = 0.0

    count = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            # é¢„æµ‹ (0-1)
            outputs = model(inputs)

            # --- åå½’ä¸€åŒ–è®¡ç®—çœŸå®ç‰©ç†è¯¯å·® ---
            # æ ‡ç­¾ Rho: 0.5æ˜¯ä¸­å¿ƒ, 0æ˜¯-Diag/2, 1æ˜¯+Diag/2
            # è¿˜åŸå…¬å¼: real_rho = (val - 0.5) * Diag
            # ä½†ä¸ºäº†ç®— MAE (ç»å¯¹è¯¯å·®)ï¼Œå¯ä»¥ç›´æ¥ç®—: abs(pred - gt) * Diag

            # Rho è¯¯å·® (åƒç´ )
            diff_rho_norm = torch.abs(outputs[:, 0] - labels[:, 0])
            # Dataseté‡Œæ˜¯ç”¨ original_diag / 2 åšåˆ†æ¯ï¼Œè¿™é‡Œè¿˜åŸå›å»
            # è¿™æ˜¯ä¸€ä¸ªè¿‘ä¼¼å€¼ï¼Œå› ä¸ºæ¯å¼ å›¾å¯¹è§’çº¿ä¸ä¸€æ ·ï¼Œä½†åœ¨è¯„ä¼°æ—¶ç”¨å¹³å‡å€¼å³å¯
            batch_mae_rho = torch.sum(diff_rho_norm * (APPROX_MAX_DIAG))

            # Theta è¯¯å·® (åº¦)
            diff_theta_norm = torch.abs(outputs[:, 1] - labels[:, 1])
            batch_mae_theta = torch.sum(diff_theta_norm * MAX_THETA_DEG)

            total_mae_rho_pixel += batch_mae_rho.item()
            total_mae_theta_degree += batch_mae_theta.item()
            count += inputs.size(0)

    avg_rho_error = total_mae_rho_pixel / count
    avg_theta_error = total_mae_theta_degree / count

    print("=" * 40)
    print(f"ğŸ“Š æµ‹è¯•é›†è¯„ä¼°ç»“æœ (å…± {count} å¼ ):")
    print(f"   å¹³å‡ Rho è¯¯å·®: {avg_rho_error:.2f} åƒç´  (åœ¨1080På›¾åƒä¸­)")
    print(f"   å¹³å‡ Theta è¯¯å·®: {avg_theta_error:.2f} åº¦")
    print("=" * 40)

    # ç»˜å›¾
    plt.plot(loss_history)
    plt.title("Training Loss")
    plt.xlabel("Epoch")
    plt.ylabel("MSE Loss")
    plt.grid(True)
    plt.show()


if __name__ == "__main__":
    train_and_evaluate()