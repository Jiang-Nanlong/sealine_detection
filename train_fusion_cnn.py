# train_fusion_cnn.py
# ------------------------------------------------------------
# Train Fusion CNN on offline cache generated by make_fusion_cache.py
# (Unified pipeline for clean / rain / fog)
#
# This version is aligned with:
#   - test.py (1024x576 UNet input, mask top-connected postprocess, canny->radon)
#   - make_fusion_cache.py (FusionCache_1024x576/{train,val,test})
#
# Key improvements vs old script:
#   1) CACHE_ROOT points to FusionCache_1024x576
#   2) strict_missing=True (missing cache files will raise -> avoid silently training on zeros)
#   3) ReduceLROnPlateau scheduler + EarlyStopping
#   4) More robust AMP (torch.amp with fallback)
# ------------------------------------------------------------

import os
import json
import random
import numpy as np
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

from cnn_model import HorizonResNet


# =========================
# Config
# =========================
# Cache root produced by the NEW make_fusion_cache.py
CACHE_ROOT = r"Hashmani's Dataset/FusionCache_1024x576"
TRAIN_CACHE_DIR = os.path.join(CACHE_ROOT, "train")
VAL_CACHE_DIR   = os.path.join(CACHE_ROOT, "val")
TEST_CACHE_DIR  = os.path.join(CACHE_ROOT, "test")

# Fixed split indices (row indices of GroundTruth.csv)
SPLIT_DIR = r"splits_musid"

SEED = 42
BATCH_SIZE = 6
NUM_EPOCHS = 40
LR = 2e-4
WEIGHT_DECAY = 1e-4
NUM_WORKERS = 2

USE_AMP = True
GRAD_CLIP_NORM = 1.0

# LR scheduler + early stop
PLATEAU_PATIENCE = 3
PLATEAU_FACTOR = 0.5
EARLY_STOP_PATIENCE = 10

# Model / log outputs
BEST_PATH = os.path.join(SPLIT_DIR, "best_fusion_cnn_1024x576.pth")
OUT_JSON  = os.path.join(SPLIT_DIR, "train_fusion_cnn_1024x576.json")

# Dataset fallback shape (should match cache input shape)
FALLBACK_SHAPE = (4, 2240, 180)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


# =========================
# Reproducibility
# =========================
def seed_everything(seed: int):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)


# =========================
# Split loader
# =========================
def load_split_indices(split_dir: str):
    """
    Prefer:
      train_indices.npy / val_indices.npy / test_indices.npy
    Also supports:
      train_idx.npy / test_idx.npy
    """
    primary = {
        "train": os.path.join(split_dir, "train_indices.npy"),
        "val":   os.path.join(split_dir, "val_indices.npy"),
        "test":  os.path.join(split_dir, "test_indices.npy"),
    }
    alt = {
        "train": os.path.join(split_dir, "train_idx.npy"),
        "test":  os.path.join(split_dir, "test_idx.npy"),
    }

    if all(os.path.exists(p) for p in primary.values()):
        return {
            "train": np.load(primary["train"]).astype(np.int64).tolist(),
            "val":   np.load(primary["val"]).astype(np.int64).tolist(),
            "test":  np.load(primary["test"]).astype(np.int64).tolist(),
        }

    if os.path.exists(alt["train"]) and os.path.exists(alt["test"]):
        return {
            "train": np.load(alt["train"]).astype(np.int64).tolist(),
            "val":   [],
            "test":  np.load(alt["test"]).astype(np.int64).tolist(),
        }

    raise FileNotFoundError(
        f"Cannot find split indices in {split_dir}. "
        f"Need train_indices/val_indices/test_indices or train_idx/test_idx."
    )


# =========================
# Dataset
# =========================
class SplitCacheDataset(Dataset):
    """
    cache_dir/{idx}.npy where each npy contains dict:
      - input: float32 [C,H,W]
      - label: float32 [2] -> (rho_norm, theta_norm)
    """
    def __init__(self, cache_dir: str, indices: list, fallback_shape=(4, 2240, 180), strict_missing: bool = True):
        self.cache_dir = cache_dir
        self.indices = list(indices)
        self.fallback_shape = tuple(fallback_shape)
        self.strict_missing = bool(strict_missing)

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, i: int):
        idx = int(self.indices[i])
        path = os.path.join(self.cache_dir, f"{idx}.npy")
        if not os.path.exists(path):
            if self.strict_missing:
                raise FileNotFoundError(f"Missing cache file: {path}")
            x = torch.zeros(self.fallback_shape, dtype=torch.float32)
            y = torch.zeros(2, dtype=torch.float32)
            return x, y

        data = np.load(path, allow_pickle=True).item()
        x = torch.from_numpy(data["input"]).float()   # [C,H,W]
        y = torch.from_numpy(data["label"]).float()   # [2]
        return x, y


# =========================
# Loss (rho linear, theta periodic)
# =========================
class HorizonPeriodicLoss(nn.Module):
    def __init__(self, rho_weight=1.0, theta_weight=2.0, rho_beta=0.02, theta_beta=0.02):
        super().__init__()
        self.rho_weight = float(rho_weight)
        self.theta_weight = float(theta_weight)
        self.rho_loss = nn.SmoothL1Loss(beta=rho_beta)
        self.theta_loss = nn.SmoothL1Loss(beta=theta_beta)

    def forward(self, preds, targets):
        # rho: linear 0~1
        loss_rho = self.rho_loss(preds[:, 0], targets[:, 0])

        # theta: 0~1 -> 0~pi (half period). Use sin/cos to measure circular distance.
        theta_p = preds[:, 1] * np.pi
        theta_t = targets[:, 1] * np.pi
        sin_p, cos_p = torch.sin(theta_p), torch.cos(theta_p)
        sin_t, cos_t = torch.sin(theta_t), torch.cos(theta_t)

        loss_theta = self.theta_loss(sin_p, sin_t) + self.theta_loss(cos_p, cos_t)
        return self.rho_weight * loss_rho + self.theta_weight * loss_theta


# =========================
# AMP helpers (torch.amp preferred)
# =========================
try:
    import torch.amp as torch_amp
    _HAS_TORCH_AMP = True
except Exception:
    _HAS_TORCH_AMP = False
    torch_amp = None


def autocast_ctx():
    if not USE_AMP or not DEVICE.startswith("cuda"):
        from contextlib import nullcontext
        return nullcontext()
    if _HAS_TORCH_AMP:
        return torch_amp.autocast(device_type="cuda", enabled=True)
    # fallback
    return torch.cuda.amp.autocast(enabled=True)


def make_scaler():
    if not USE_AMP or not DEVICE.startswith("cuda"):
        return None
    if _HAS_TORCH_AMP:
        try:
            return torch_amp.GradScaler(device="cuda", enabled=True)
        except TypeError:
            return torch_amp.GradScaler(enabled=True)
    return torch.cuda.amp.GradScaler(enabled=True)


# =========================
# Train / Eval
# =========================
@torch.no_grad()
def evaluate(model, loader, criterion):
    model.eval()
    total_loss = 0.0
    n = 0
    for x, y in loader:
        x = x.to(DEVICE, non_blocking=True)
        y = y.to(DEVICE, non_blocking=True)
        with autocast_ctx():
            pred = model(x)
            loss = criterion(pred, y)
        total_loss += float(loss.item()) * x.size(0)
        n += x.size(0)
    return total_loss / max(1, n)


def train_one_epoch(model, loader, optimizer, scaler, criterion):
    model.train()
    total_loss = 0.0
    n = 0

    for x, y in tqdm(loader, desc="train", ncols=90):
        x = x.to(DEVICE, non_blocking=True)
        y = y.to(DEVICE, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)

        if scaler is not None:
            with autocast_ctx():
                pred = model(x)
                loss = criterion(pred, y)
            scaler.scale(loss).backward()
            if GRAD_CLIP_NORM and GRAD_CLIP_NORM > 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)
            scaler.step(optimizer)
            scaler.update()
        else:
            pred = model(x)
            loss = criterion(pred, y)
            loss.backward()
            if GRAD_CLIP_NORM and GRAD_CLIP_NORM > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)
            optimizer.step()

        total_loss += float(loss.item()) * x.size(0)
        n += x.size(0)

    return total_loss / max(1, n)


# =========================
# Main
# =========================
def main():
    seed_everything(SEED)
    ensure_dir(SPLIT_DIR)

    # sanity check dirs
    for d in [TRAIN_CACHE_DIR, VAL_CACHE_DIR]:
        if not os.path.isdir(d):
            raise FileNotFoundError(f"Cache dir not found: {d}")
    has_test = os.path.isdir(TEST_CACHE_DIR)
    if not has_test:
        print(f"[WARN] TEST_CACHE_DIR not found: {TEST_CACHE_DIR} (skip final test eval)")

    # 1) splits
    splits = load_split_indices(SPLIT_DIR)
    train_indices = splits["train"]
    val_indices = splits.get("val", [])
    test_indices = splits.get("test", [])

    if len(val_indices) == 0:
        raise RuntimeError(
            "val_indices is empty. Please generate train/val/test splits (make_musid_splits.py). "
            "Using a val split is important for stable best model selection."
        )

    # 2) dataset/loader
    train_ds = SplitCacheDataset(TRAIN_CACHE_DIR, train_indices, fallback_shape=FALLBACK_SHAPE, strict_missing=True)
    val_ds   = SplitCacheDataset(VAL_CACHE_DIR,   val_indices,   fallback_shape=FALLBACK_SHAPE, strict_missing=True)
    test_ds  = SplitCacheDataset(TEST_CACHE_DIR,  test_indices,  fallback_shape=FALLBACK_SHAPE, strict_missing=True) if has_test else None

    pin = DEVICE.startswith("cuda")
    train_loader = DataLoader(
        train_ds, batch_size=BATCH_SIZE, shuffle=True,
        num_workers=NUM_WORKERS, pin_memory=pin, drop_last=True
    )
    val_loader = DataLoader(
        val_ds, batch_size=BATCH_SIZE, shuffle=False,
        num_workers=NUM_WORKERS, pin_memory=pin
    )
    test_loader = DataLoader(
        test_ds, batch_size=BATCH_SIZE, shuffle=False,
        num_workers=NUM_WORKERS, pin_memory=pin
    ) if test_ds is not None else None

    # 3) model
    x0, _ = train_ds[0]
    in_ch = int(x0.shape[0])
    model = HorizonResNet(in_channels=in_ch).to(DEVICE)

    criterion = HorizonPeriodicLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
    scaler = make_scaler()

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", factor=PLATEAU_FACTOR, patience=PLATEAU_PATIENCE, verbose=True
    )

    # 4) train
    best_val = float("inf")
    best_epoch = 0
    bad_epochs = 0
    history = []

    print(f"[INFO] DEVICE={DEVICE}  AMP={USE_AMP and DEVICE.startswith('cuda')}")
    print(f"[INFO] CacheRoot={CACHE_ROOT}")
    print(f"[INFO] Train={len(train_ds)}  Val={len(val_ds)}  Test={(len(test_ds) if test_ds is not None else 0)}")
    print(f"[INFO] in_channels={in_ch}  epochs={NUM_EPOCHS}  bs={BATCH_SIZE}  lr={LR}")

    for epoch in range(1, NUM_EPOCHS + 1):
        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler, criterion)
        va_loss = evaluate(model, val_loader, criterion)

        lr_now = optimizer.param_groups[0]["lr"]
        print(f"Epoch [{epoch:03d}/{NUM_EPOCHS}]  lr={lr_now:.2e}  train_loss={tr_loss:.6f}  val_loss={va_loss:.6f}")

        history.append({"epoch": epoch, "lr": lr_now, "train_loss": tr_loss, "val_loss": va_loss})

        scheduler.step(va_loss)

        if va_loss < best_val - 1e-8:
            best_val = va_loss
            best_epoch = epoch
            bad_epochs = 0
            torch.save(model.state_dict(), BEST_PATH)
            print(f"  -> best updated: {best_val:.6f} (epoch={best_epoch})  saved={BEST_PATH}")
        else:
            bad_epochs += 1
            if bad_epochs >= EARLY_STOP_PATIENCE:
                print(f"[EARLY STOP] no improvement for {EARLY_STOP_PATIENCE} epochs. best_epoch={best_epoch}")
                break

    # 5) final test eval
    final_test = None
    if test_loader is not None and os.path.exists(BEST_PATH):
        model.load_state_dict(torch.load(BEST_PATH, map_location=DEVICE))
        final_test = evaluate(model, test_loader, criterion)
        print(f"[FINAL TEST] loss={final_test:.6f}")
    else:
        print("[FINAL] test skipped")

    payload = {
        "cache_root": CACHE_ROOT,
        "train_cache_dir": TRAIN_CACHE_DIR,
        "val_cache_dir": VAL_CACHE_DIR,
        "test_cache_dir": TEST_CACHE_DIR if has_test else None,
        "split_dir": SPLIT_DIR,
        "seed": SEED,
        "batch_size": BATCH_SIZE,
        "num_epochs": NUM_EPOCHS,
        "lr": LR,
        "weight_decay": WEIGHT_DECAY,
        "use_amp": bool(USE_AMP and DEVICE.startswith("cuda")),
        "grad_clip_norm": GRAD_CLIP_NORM,
        "scheduler": {
            "type": "ReduceLROnPlateau",
            "patience": PLATEAU_PATIENCE,
            "factor": PLATEAU_FACTOR
        },
        "early_stop_patience": EARLY_STOP_PATIENCE,
        "in_channels": in_ch,
        "best_val_loss": best_val,
        "best_epoch": best_epoch,
        "test_loss": final_test,
        "best_model_path": BEST_PATH,
        "history": history,
    }
    with open(OUT_JSON, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
    print(f"[SAVE] {OUT_JSON}")


if __name__ == "__main__":
    main()
