# -*- coding: utf-8 -*-
"""
evaluate_three_weights_cnnonly.py
------------------------------------------------------------
Evaluate 3 trained CNN weights on FusionCache test split:
  - best_fusion_cnn_1024x576.pth        (4ch: [0,1,2,3])
  - best_fusion_cnn_1024x576_trad3.pth  (3ch: [0,1,2])
  - best_fusion_cnn_1024x576_seg1.pth   (1ch: [3])

This script computes CNN-only metrics (no UNet / no RANSAC refine):
  - rho abs error (orig approx px): mean, p95
  - edgeY error (orig approx px): mean, p95
  - line mean point->line distance (orig approx px): mean
  - threshold stats: rho<=10, edge<=5, edge<=10  (orig approx px)

Outputs:
  OUT_DIR/
    summary.csv
    fusion4/per_sample.csv
    trad3/per_sample.csv
    seg1/per_sample.csv

PyCharm-friendly: edit CONFIG below then Run.
------------------------------------------------------------
"""

import os
import math
import csv
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple, Dict, Any

import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader

from cnn_model import HorizonResNet
from pathlib import Path
import sys

# =========================
# ===== PATH SETUP =========
# =========================
THIS_DIR = Path(__file__).resolve().parent          # .../sealine_detection/test_3
PROJECT_ROOT = THIS_DIR.parent                      # .../sealine_detection

# 让脚本在 test_3 下运行时也能 import cnn_model 等工程文件
sys.path.insert(0, str(PROJECT_ROOT))

# =========================
# ====== CONFIG ===========
# =========================

# FusionCache test folder (generated by make_fusion_cache.py)
CACHE_DIR = str(PROJECT_ROOT / "Hashmani's Dataset" / "FusionCache_1024x576" / "test")

# Output folder: everything for this experiment stays inside test_3
OUT_DIR = str(THIS_DIR / "outputs")

# 3 weights to evaluate
WEIGHT_CONFIGS = [
    dict(name="fusion4", weights=str(PROJECT_ROOT / "weights" / "best_fusion_cnn_1024x576.pth"),       channels=[0, 1, 2, 3]),
    dict(name="trad3",   weights=str(PROJECT_ROOT / "weights" / "best_fusion_cnn_1024x576_trad3.pth"), channels=[0, 1, 2]),
    dict(name="seg1",    weights=str(PROJECT_ROOT / "weights" / "best_fusion_cnn_1024x576_seg1.pth"),  channels=[3]),
]

# Runtime
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 64
NUM_WORKERS = 0  # Windows safe
USE_AMP = True

# Geometry (must match make_fusion_cache.py)
UNET_W = 1024
UNET_H = 576
RESIZE_H = 2240
ANGLE_RANGE_DEG = 180.0

# Original-scale approx (your dataset ground truth is 1920x1080)
ORIG_W = 1920
ORIG_H = 1080


# =========================
# ===== Dataset ===========
# =========================
class FusionCacheDataset(Dataset):
    """
    Each cache file {idx}.npy is a dict with keys:
      - "input": (4,2240,180) float32
      - "label": (2,) float32 [rho_norm, theta_norm]
      - "img_name": optional
    """
    def __init__(self, cache_dir: str):
        self.files = sorted([str(p) for p in Path(cache_dir).glob("*.npy")],
                            key=lambda s: int(Path(s).stem))

    def __len__(self):
        return len(self.files)

    def __getitem__(self, i: int):
        path = self.files[i]
        obj = np.load(path, allow_pickle=True)
        if isinstance(obj, np.ndarray) and obj.dtype == object:
            obj = obj.item()

        if not isinstance(obj, dict):
            raise RuntimeError(f"Unexpected cache format: {path}")

        x = obj.get("input", obj.get("x", None))
        y = obj.get("label", obj.get("y", None))
        img_name = obj.get("img_name", None)

        if x is None or y is None:
            raise RuntimeError(f"Missing input/label in cache: {path}")

        if img_name is None:
            img_name = Path(path).stem + ".jpg"

        x = torch.from_numpy(np.asarray(x, dtype=np.float32))  # [4,H,W]
        y = torch.from_numpy(np.asarray(y, dtype=np.float32))  # [2]
        return x, y, str(img_name), str(path)


# =========================
# ===== Denorm ============
# =========================
@dataclass
class DenormConfig:
    unet_w: int = UNET_W
    unet_h: int = UNET_H
    resize_h: int = RESIZE_H
    angle_range_deg: float = ANGLE_RANGE_DEG


def denorm_rho_theta(rho_norm: np.ndarray, theta_norm: np.ndarray, cfg: DenormConfig) -> Tuple[np.ndarray, np.ndarray]:
    """
    Match make_fusion_cache.py::calculate_radon_label (inverse mapping).

    Returns:
      rho_real (px) : signed distance in centered UNet coords
      theta_deg     : in [0,180)
    """
    w, h = cfg.unet_w, cfg.unet_h
    diag = math.sqrt(w * w + h * h)
    pad_top = (cfg.resize_h - diag) / 2.0

    final_rho_idx = rho_norm * (cfg.resize_h - 1.0)
    rho_real = final_rho_idx - pad_top - (diag / 2.0)
    theta_deg = (theta_norm * cfg.angle_range_deg) % cfg.angle_range_deg
    return rho_real, theta_deg


def wrap_angle_deg(err_deg: float, period: float = 180.0) -> float:
    e = abs(err_deg) % period
    return min(e, period - e)


# =========================
# ===== Line metrics ======
# =========================
def line_intersections_in_image(rho: float, theta_deg: float, w: int, h: int, eps: float = 1e-8) -> List[Tuple[float, float]]:
    theta = math.radians(theta_deg)
    cos_t, sin_t = math.cos(theta), math.sin(theta)
    cx, cy = w / 2.0, h / 2.0
    pts = []

    # x=0
    if abs(sin_t) > eps:
        y = cy + (rho - ((0.0 - cx) * cos_t)) / sin_t
        if -1 <= y <= h:
            pts.append((0.0, float(y)))
    # x=w-1
    if abs(sin_t) > eps:
        x = w - 1.0
        y = cy + (rho - ((x - cx) * cos_t)) / sin_t
        if -1 <= y <= h:
            pts.append((x, float(y)))
    # y=0
    if abs(cos_t) > eps:
        y = 0.0
        x = cx + (rho - ((y - cy) * sin_t)) / cos_t
        if -1 <= x <= w:
            pts.append((float(x), y))
    # y=h-1
    if abs(cos_t) > eps:
        y = h - 1.0
        x = cx + (rho - ((y - cy) * sin_t)) / cos_t
        if -1 <= x <= w:
            pts.append((float(x), y))

    pts2 = []
    for x, y in pts:
        if 0.0 <= x <= (w - 1.0) and 0.0 <= y <= (h - 1.0):
            pts2.append((x, y))
    return pts2


def farthest_pair(pts: List[Tuple[float, float]]) -> Tuple[Tuple[float, float], Tuple[float, float]]:
    best = (pts[0], pts[1])
    best_d2 = -1.0
    for i in range(len(pts)):
        for j in range(i + 1, len(pts)):
            dx = pts[i][0] - pts[j][0]
            dy = pts[i][1] - pts[j][1]
            d2 = dx * dx + dy * dy
            if d2 > best_d2:
                best_d2 = d2
                best = (pts[i], pts[j])
    return best


def mean_point_to_line_distance(
    rho_pred: float, theta_pred_deg: float,
    rho_gt: float, theta_gt_deg: float,
    w: int, h: int, n_samples: int = 50
) -> float:
    pts = line_intersections_in_image(rho_gt, theta_gt_deg, w, h)
    if len(pts) >= 2:
        p0, p1 = farthest_pair(pts)
    else:
        theta = math.radians(theta_gt_deg)
        cos_t, sin_t = math.cos(theta), math.sin(theta)
        cx, cy = w / 2.0, h / 2.0
        x0, x1 = 0.0, w - 1.0
        if abs(sin_t) < 1e-8:
            y0 = y1 = cy
        else:
            y0 = cy + (rho_gt - ((x0 - cx) * cos_t)) / sin_t
            y1 = cy + (rho_gt - ((x1 - cx) * cos_t)) / sin_t
        y0 = float(np.clip(y0, 0, h - 1))
        y1 = float(np.clip(y1, 0, h - 1))
        p0, p1 = (x0, y0), (x1, y1)

    xs = np.linspace(p0[0], p1[0], n_samples)
    ys = np.linspace(p0[1], p1[1], n_samples)

    theta_p = math.radians(theta_pred_deg)
    cos_p, sin_p = math.cos(theta_p), math.sin(theta_p)
    cx, cy = w / 2.0, h / 2.0

    x_c = xs - cx
    y_c = ys - cy
    d = np.abs(x_c * cos_p + y_c * sin_p - rho_pred)
    return float(np.mean(d))


def edge_y_at_x(rho: float, theta_deg: float, x: float, w: int, h: int) -> float:
    theta = math.radians(theta_deg)
    cos_t, sin_t = math.cos(theta), math.sin(theta)
    cx, cy = w / 2.0, h / 2.0
    if abs(sin_t) < 1e-8:
        return float(cy)
    y = cy + (rho - ((x - cx) * cos_t)) / sin_t
    return float(np.clip(y, 0.0, h - 1.0))


def edge_y_error(
    rho_pred: float, theta_pred_deg: float,
    rho_gt: float, theta_gt_deg: float,
    w: int, h: int
) -> float:
    ypl = edge_y_at_x(rho_pred, theta_pred_deg, 0.0, w, h)
    ypr = edge_y_at_x(rho_pred, theta_pred_deg, w - 1.0, w, h)
    ygl = edge_y_at_x(rho_gt, theta_gt_deg, 0.0, w, h)
    ygr = edge_y_at_x(rho_gt, theta_gt_deg, w - 1.0, w, h)
    return float(0.5 * (abs(ypl - ygl) + abs(ypr - ygr)))


# =========================
# ===== Model load =========
# =========================
def load_state_dict_flexible(weights_path: str) -> Dict[str, torch.Tensor]:
    try:
        ckpt = torch.load(weights_path, map_location="cpu", weights_only=False)
    except TypeError:
        ckpt = torch.load(weights_path, map_location="cpu")

    # common wrappers
    if isinstance(ckpt, dict) and "state_dict" in ckpt:
        ckpt = ckpt["state_dict"]
    if isinstance(ckpt, dict) and "model" in ckpt:
        ckpt = ckpt["model"]

    if not isinstance(ckpt, dict):
        raise RuntimeError(f"Unsupported checkpoint format: {weights_path}")

    # strip "module." if needed
    if any(k.startswith("module.") for k in ckpt.keys()):
        ckpt = {k.replace("module.", "", 1): v for k, v in ckpt.items()}

    return ckpt


def load_model(weights_path: str, in_channels: int) -> HorizonResNet:
    model = HorizonResNet(in_channels=in_channels).to(DEVICE)
    state = load_state_dict_flexible(weights_path)
    model.load_state_dict(state, strict=True)
    model.eval()
    return model


# =========================
# ===== Eval helpers ======
# =========================
def summarize_basic(x: np.ndarray) -> Dict[str, float]:
    return dict(
        mean=float(np.mean(x)),
        median=float(np.median(x)),
        p90=float(np.percentile(x, 90)),
        p95=float(np.percentile(x, 95)),
        max=float(np.max(x)),
    )


def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)


@torch.no_grad()
def eval_one(weights_path: str, channels: List[int], out_subdir: str) -> Dict[str, Any]:
    cfg = DenormConfig()
    ds = FusionCacheDataset(CACHE_DIR)
    loader = DataLoader(
        ds,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS,
        pin_memory=(DEVICE.startswith("cuda")),
    )

    model = load_model(weights_path, in_channels=len(channels))

    # orig approx scale (match your full-pipeline script: average sx/sy)
    sx = ORIG_W / float(UNET_W)
    sy = ORIG_H / float(UNET_H)
    scale_orig = 0.5 * (sx + sy)

    rows = []
    rho_err_unet = []
    theta_err = []
    line_dist_unet = []
    edgey_unet = []
    rho_pred_list = []
    theta_pred_list = []
    rho_gt_list = []
    theta_gt_list = []

    use_amp = USE_AMP and DEVICE.startswith("cuda")
    autocast = torch.cuda.amp.autocast if DEVICE.startswith("cuda") else None

    for xb, yb, img_names, cache_files in loader:
        xb = xb.to(DEVICE, non_blocking=True)  # [B,4,H,W]
        yb = yb.to(DEVICE, non_blocking=True)  # [B,2]

        xb = xb[:, channels, :, :].contiguous()

        if use_amp:
            with autocast():
                pred, conf = model(xb, return_conf=True)
        else:
            pred, conf = model(xb, return_conf=True)

        pred_np = pred.detach().cpu().numpy()
        gt_np = yb.detach().cpu().numpy()
        conf_np = conf.detach().cpu().numpy().reshape(-1)

        # denorm to (rho_real_px, theta_deg)
        rho_pr, th_pr = denorm_rho_theta(pred_np[:, 0], pred_np[:, 1], cfg)
        rho_gt, th_gt = denorm_rho_theta(gt_np[:, 0], gt_np[:, 1], cfg)

        for i in range(pred_np.shape[0]):
            rp = float(rho_pr[i]); tp = float(th_pr[i])
            rg = float(rho_gt[i]); tg = float(th_gt[i])

            re = abs(rp - rg)
            te = wrap_angle_deg(tp - tg, period=ANGLE_RANGE_DEG)
            ld = mean_point_to_line_distance(rp, tp, rg, tg, UNET_W, UNET_H)
            ey = edge_y_error(rp, tp, rg, tg, UNET_W, UNET_H)

            rho_err_unet.append(re)
            theta_err.append(te)
            line_dist_unet.append(ld)
            edgey_unet.append(ey)

            rho_pred_list.append(rp); theta_pred_list.append(tp)
            rho_gt_list.append(rg);   theta_gt_list.append(tg)

            rows.append(dict(
                img_name=str(img_names[i]),
                cache_file=str(cache_files[i]),
                conf=float(conf_np[i]),

                rho_gt=float(rg),
                theta_gt=float(tg),
                rho_pred=float(rp),
                theta_pred=float(tp),

                rho_abs_px_unet=float(re),
                theta_err_deg=float(te),
                line_dist_px_unet=float(ld),
                edgey_px_unet=float(ey),

                rho_abs_px_orig=float(re * scale_orig),
                line_dist_px_orig=float(ld * scale_orig),
                edgey_px_orig=float(ey * scale_orig),
            ))

    # numpy
    rho_err_unet = np.array(rho_err_unet, dtype=np.float64)
    theta_err = np.array(theta_err, dtype=np.float64)
    line_dist_unet = np.array(line_dist_unet, dtype=np.float64)
    edgey_unet = np.array(edgey_unet, dtype=np.float64)

    rho_err_orig = rho_err_unet * scale_orig
    line_dist_orig = line_dist_unet * scale_orig
    edgey_orig = edgey_unet * scale_orig

    # Save per-sample csv
    ensure_dir(out_subdir)
    per_csv = os.path.join(out_subdir, "per_sample.csv")
    with open(per_csv, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))
        w.writeheader()
        for r in rows:
            w.writerow(r)

    # Summary stats (match your论文表格口径：用 orig approx px)
    summary = {
        "weights": weights_path,
        "channels": str(channels),
        "N": int(len(rows)),

        "rhoMean": float(np.mean(rho_err_orig)),
        "rhoP95": float(np.percentile(rho_err_orig, 95)),

        "edgeMean": float(np.mean(edgey_orig)),
        "edgeP95": float(np.percentile(edgey_orig, 95)),

        "lineMean": float(np.mean(line_dist_orig)),

        "rho<=10": float(np.mean(rho_err_orig <= 10.0) * 100.0),
        "edge<=5": float(np.mean(edgey_orig <= 5.0) * 100.0),
        "edge<=10": float(np.mean(edgey_orig <= 10.0) * 100.0),

        # extra (optional but useful)
        "thetaMean(deg)": float(np.mean(theta_err)),
        "thetaP95(deg)": float(np.percentile(theta_err, 95)),
        "per_sample_csv": per_csv,
    }

    return summary


def main():
    ensure_dir(OUT_DIR)
    print(f"[INFO] CACHE_DIR={CACHE_DIR}")
    print(f"[INFO] DEVICE={DEVICE} AMP={USE_AMP and DEVICE.startswith('cuda')}")
    print(f"[INFO] OUT_DIR={OUT_DIR}\n")

    all_summaries = []

    for cfg in WEIGHT_CONFIGS:
        name = cfg["name"]
        wpath = cfg["weights"]
        ch = cfg["channels"]

        out_sub = os.path.join(OUT_DIR, name)
        print(f"========== Evaluating: {name} ==========")
        print(f"  weights:  {wpath}")
        print(f"  channels: {ch}")
        s = eval_one(wpath, ch, out_sub)

        # pretty print key numbers
        print(f"  -> rhoMean={s['rhoMean']:.4f} | rhoP95={s['rhoP95']:.4f}")
        print(f"  -> edgeMean={s['edgeMean']:.4f} | edgeP95={s['edgeP95']:.4f}")
        print(f"  -> lineMean={s['lineMean']:.4f}")
        print(f"  -> rho<=10={s['rho<=10']:.2f}% | edge<=5={s['edge<=5']:.2f}% | edge<=10={s['edge<=10']:.2f}%")
        print(f"  -> thetaMean={s['thetaMean(deg)']:.4f} | thetaP95={s['thetaP95(deg)']:.4f}")
        print(f"  -> per-sample: {s['per_sample_csv']}\n")

        s_row = {"name": name, **s}
        all_summaries.append(s_row)

    # Save summary.csv
    summary_csv = os.path.join(OUT_DIR, "summary.csv")
    keys = list(all_summaries[0].keys())
    with open(summary_csv, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=keys)
        w.writeheader()
        for r in all_summaries:
            w.writerow(r)

    print(f"[SAVED] {summary_csv}")
    print("Done.")


if __name__ == "__main__":
    main()
